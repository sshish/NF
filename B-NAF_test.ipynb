{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of realNVP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D34fxkr0shR",
        "colab_type": "code",
        "outputId": "143cb077-2cb9-48d6-cafb-ca67aca4773f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/colab/NF')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfSC-_Kd3inm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "2df0919e-0f1d-452d-fbd0-56b13593f627"
      },
      "source": [
        "!pip install torch --upgrade"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 19kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.1.0\n",
            "    Uninstalling torch-1.1.0:\n",
            "      Successfully uninstalled torch-1.1.0\n",
            "Successfully installed torch-1.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0ef2c93a-07a7-40b5-cd8a-5c1e1e318e76",
        "id": "nH5yuzMevI7G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "#Define the model.\n",
        "import torch\n",
        "\n",
        "import NF #module for normalizing flows\n",
        "import BAM #module for blockwise autoregressive monotonic transformations\n",
        "\n",
        "mylayers = [BAM.LinearWeightNorm([1,1], [10,10]), BAM.Tanh([10,10]),\n",
        "            BAM.LinearWeightNorm([10,10], [10,10]), BAM.Tanh([10,10]),\n",
        "            BAM.LinearWeightNorm([10,10], [10,10]), BAM.Tanh([10,10]),\n",
        "            BAM.LinearWeightNorm([10,10], [10,10]), BAM.Tanh([10,10]),\n",
        "            BAM.LinearWeightNorm([10,10], [1,1]), BAM.Gate([1,1])\n",
        "           ]\n",
        "\n",
        "mystack = BAM.Stack(*mylayers)\n",
        "\n",
        "mycat = BAM.Cat(mystack, BAM.Gate([1,1]))\n",
        "\n",
        "mysum = BAM.Stack(mycat, BAM.Sum([2,2]))\n",
        "\n",
        "mynet = mysum.NF()\n",
        "\n",
        "mynet.bisection_minimum = torch.empty(2).fill_(-5)\n",
        "mynet.bisection_maximum = torch.empty(2).fill_(5)\n",
        "mynet.bisection_max_iterations = 12\n",
        "\n",
        "mylayers = [BAM.LinearWeightNorm([1,1], [10,10]), BAM.Tanh([10,10]),\n",
        "            BAM.LinearWeightNorm([10,10], [10,10]), BAM.Tanh([10,10]),\n",
        "            BAM.LinearWeightNorm([10,10], [10,10]), BAM.Tanh([10,10]),\n",
        "            BAM.LinearWeightNorm([10,10], [10,10]), BAM.Tanh([10,10]),\n",
        "            BAM.LinearWeightNorm([10,10], [1,1]), BAM.Gate([1,1])\n",
        "           ]\n",
        "\n",
        "mystack = BAM.Stack(*mylayers)\n",
        "\n",
        "mycat = BAM.Cat(mystack, BAM.Gate([1,1]))\n",
        "\n",
        "mysum = BAM.Stack(mycat, BAM.Sum([2,2]))\n",
        "\n",
        "mynet2 = mysum.NF()\n",
        "\n",
        "mynet = NF.Stack(NF.Rotation(0,1), NF.Tanh(), mynet, NF.Rotation(0,1), NF.Tanh(), mynet2)\n",
        "\n",
        "#I put NF.Tanh before each of the BAM.Stacks to make sure the BAM modules receive\n",
        "# normailzed input so bisection can be initialized with a known range of (-1,+1).\n",
        "# Alternatively, I can change mynet.bisection_minimum and maximum to large enough values.\n",
        "\n",
        "#NF.Rotation modules can e.g. be replaced with NF.Permutation.\n",
        "\n",
        "mynet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Stack(\n",
              "  (0): Rotation()\n",
              "  (1): Tanh()\n",
              "  (2): ToNF(\n",
              "    (_net): Stack(\n",
              "      (0): Cat(\n",
              "        (0): Stack(\n",
              "          (0): LinearWeightNorm()\n",
              "          (1): Tanh()\n",
              "          (2): LinearWeightNorm()\n",
              "          (3): Tanh()\n",
              "          (4): LinearWeightNorm()\n",
              "          (5): Tanh()\n",
              "          (6): LinearWeightNorm()\n",
              "          (7): Tanh()\n",
              "          (8): LinearWeightNorm()\n",
              "          (9): Gate()\n",
              "        )\n",
              "        (1): Gate()\n",
              "      )\n",
              "      (1): Sum()\n",
              "    )\n",
              "  )\n",
              "  (3): Rotation()\n",
              "  (4): Tanh()\n",
              "  (5): ToNF(\n",
              "    (_net): Stack(\n",
              "      (0): Cat(\n",
              "        (0): Stack(\n",
              "          (0): LinearWeightNorm()\n",
              "          (1): Tanh()\n",
              "          (2): LinearWeightNorm()\n",
              "          (3): Tanh()\n",
              "          (4): LinearWeightNorm()\n",
              "          (5): Tanh()\n",
              "          (6): LinearWeightNorm()\n",
              "          (7): Tanh()\n",
              "          (8): LinearWeightNorm()\n",
              "          (9): Gate()\n",
              "        )\n",
              "        (1): Gate()\n",
              "      )\n",
              "      (1): Sum()\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-Qetl29ElIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "7d97433f-3516-403d-9036-c988a4ea0f55"
      },
      "source": [
        "#Train the model on the \"moons\" dataset from keras.\n",
        "device = torch.device(\"cuda\")\n",
        "prior = torch.distributions.MultivariateNormal(torch.zeros(2).to(device), torch.eye(2).to(device))\n",
        "mygen = NF.ToGenerator(mynet, prior).to(device)\n",
        "optimizer = torch.optim.Adam(mygen.parameters())\n",
        "batches = 10000\n",
        "batchsize = 100\n",
        "\n",
        "import sklearn.datasets\n",
        "import numpy\n",
        "\n",
        "for t in range(batches):\n",
        "  noisy_moons = torch.from_numpy(sklearn.datasets.make_moons(n_samples=batchsize, noise=0.05)[0].astype(numpy.float32)).to(device)\n",
        "  loss = mygen.crossentropy_loss(noisy_moons)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  if (t%500 == 0):\n",
        "    print(t, loss.item())\n",
        "  optimizer.step()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 19.224088668823242\n",
            "500 3.494838237762451\n",
            "1000 2.212899684906006\n",
            "1500 1.6343508958816528\n",
            "2000 1.266158938407898\n",
            "2500 1.1572132110595703\n",
            "3000 1.0011813640594482\n",
            "3500 0.8813275098800659\n",
            "4000 0.9920436143875122\n",
            "4500 0.8582861423492432\n",
            "5000 0.6817704439163208\n",
            "5500 0.6903846859931946\n",
            "6000 0.5744314193725586\n",
            "6500 0.5384166240692139\n",
            "7000 0.5635965466499329\n",
            "7500 0.48404791951179504\n",
            "8000 0.5172460079193115\n",
            "8500 0.5165607333183289\n",
            "9000 0.45049017667770386\n",
            "9500 0.5007658004760742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Frr9EF6UvI7Q",
        "outputId": "ea6f598a-2f5d-44b9-9b34-9049a345cd0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "#Generate samples from the learned distribution.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = mygen.sample(1000).detach().cpu().numpy()\n",
        "plt.scatter(x[:,0], x[:,1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7ff9d00e76d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMEgCIIg1PH/AVepRGNDq9E3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HoFCh4xg2L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Helper functions for initialization of (stacks of) coupling layers.\n",
        "import torch\n",
        "\n",
        "def create_mask(n, p=0.5):\n",
        "  idx = torch.randperm(n)\n",
        "  mask = torch.where(idx > p * (n - 1), torch.ones_like(idx), torch.zeros_like(idx)).bool()\n",
        "  return mask\n",
        "\n",
        "def create_t(n, h=[256,256]):\n",
        "  net = torch.nn.Linear(n, h[0])\n",
        "  for layer in range(1, len(h)):\n",
        "    net = torch.nn.Sequential(net, torch.nn.LeakyReLU(), torch.nn.Linear(h[layer-1], h[layer]))\n",
        "  net = torch.nn.Sequential(net, torch.nn.LeakyReLU(), torch.nn.Linear(h[-1], n))\n",
        "  return net\n",
        "\n",
        "def create_s(n, h=[256,256]):\n",
        "  net = create_t(n, h)\n",
        "  net = torch.nn.Sequential(net, torch.nn.Tanh())\n",
        "  return net\n",
        "  \n",
        "def create_2cl(n, p=0.5, ht=[256,256], hs=[256,256]):\n",
        "  mask = create_mask(n, p)\n",
        "  t1 = create_t(n, ht)\n",
        "  t2 = create_t(n, ht)\n",
        "  s1 = create_s(n, hs)\n",
        "  s2 = create_s(n, hs)\n",
        "  cl1 = NFCouplingLayer(s1, t1, mask)\n",
        "  cl2 = NFCouplingLayer(s2, t2, ~mask)\n",
        "  return NFStack(cl1, cl2)\n",
        "\n",
        "def create_flownet(n, d=3, p=None, ht=None, hs=None):\n",
        "  if p is None: p = [0.5] * d\n",
        "  if ht is None: ht = [[256,256]] * d\n",
        "  if hs is None: hs = [[256,256]] * d\n",
        "  assert(len(p) == len(ht) == len(hs) == d)\n",
        "  net = create_2cl(n, p[0], ht[0], hs[0])\n",
        "  for i in range(1, d):\n",
        "    net.add_module(str(i), create_2cl(n, p[i], ht[i], hs[i]))\n",
        "  return net\n",
        "\n",
        "n = 2\n",
        "mynet = create_flownet(n)\n",
        "\n",
        "mynet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg3-hjNhg3WS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train model on the \"moons\" dataset from keras.\n",
        "device = torch.device(\"cuda\")\n",
        "prior = torch.distributions.MultivariateNormal(torch.zeros(n).to(device), torch.eye(n).to(device))\n",
        "mygen = NFGenerator(mynet, prior).to(device)\n",
        "optimizer = torch.optim.Adam(mygen.parameters())\n",
        "batches = 10000\n",
        "batchsize = 100\n",
        "\n",
        "import sklearn.datasets\n",
        "import numpy\n",
        "\n",
        "for t in range(batches):\n",
        "  noisy_moons = torch.from_numpy(sklearn.datasets.make_moons(n_samples=batchsize, noise=0.05)[0].astype(numpy.float32)).to(device)\n",
        "  #we need noise because data distribution needs to be smooth enough for our model to fit\n",
        "  loss = mygen.crossentropy_loss(noisy_moons)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  if (t%500 == 0):\n",
        "    print(t, loss.item())\n",
        "  optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KSErbKNhDq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Generate samples from learned distribution.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = mygen.sample(1000).detach().cpu().numpy()\n",
        "plt.scatter(x[:,0], x[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}